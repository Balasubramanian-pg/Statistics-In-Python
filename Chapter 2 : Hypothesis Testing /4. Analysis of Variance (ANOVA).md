### **Analysis of Variance (ANOVA)**

**ANOVA** is a statistical method used to compare the means of **three or more independent groups** to determine if at least one group mean is significantly different from the others. It extends the independent samples t-test to more than two groups.

---

### **When to Use ANOVA**
- You have **three or more independent groups** (e.g., Group A, Group B, Group C).
- You want to test if the **means of a continuous variable** differ across these groups.
- Your data is **normally distributed** within each group.
- The groups have **similar variances** (homogeneity of variance).

---

### **Key Assumptions**
- **Independence**: Observations in each group are independent.
- **Normality**: The dependent variable is approximately normally distributed within each group.
- **Homogeneity of Variance**: The variances of the groups are equal (tested using Levene’s test).

---

### **Hypotheses**
- **Null Hypothesis (H₀)**: All group means are equal.
  \( H_0: \mu_1 = \mu_2 = \mu_3 = ... = \mu_k \)
- **Alternative Hypothesis (H₁)**: At least one group mean is different.

---

### **Types of ANOVA**
1. **One-Way ANOVA**: Compares means across **one independent variable** (e.g., drug dosage levels).
2. **Two-Way ANOVA**: Compares means across **two independent variables** (e.g., drug dosage and gender).
3. **Repeated Measures ANOVA**: Used for **dependent groups** (e.g., before/after measurements for multiple time points).

---

### **Steps to Perform One-Way ANOVA**
1. **State your hypotheses**.
2. **Set the significance level (α)**, usually 0.05.
3. **Check assumptions** (normality and homogeneity of variance).
4. **Calculate the F-statistic**:
   - **Between-group variability**: Differences between group means.
   - **Within-group variability**: Differences within each group.
   - \( F = \frac{\text{Between-group variability}}{\text{Within-group variability}} \)
5. **Determine the degrees of freedom**:
   - Between groups: \( df_b = k - 1 \) (k = number of groups)
   - Within groups: \( df_w = N - k \) (N = total sample size)
6. **Compare the F-statistic to the critical F-value** or calculate the p-value.
7. **Make a decision**:
   - If \( p \leq \alpha \), reject the null hypothesis (at least one group differs).
   - If \( p > \alpha \), fail to reject the null hypothesis.

---

### **Example**
Suppose you compare test scores for three teaching methods (A, B, C):

| Method A | Method B | Method C |
|----------|----------|----------|
| 85       | 90       | 78       |
| 90       | 88       | 82       |
| 88       | 92       | 80       |

- Calculate the **sum of squares between groups (SSB)** and **sum of squares within groups (SSW)**.
- Compute the **mean square between (MSB)** and **mean square within (MSW)**.
- \( F = \frac{MSB}{MSW} \)

If \( F \) is significant, perform **post-hoc tests** (e.g., Tukey’s HSD) to identify which groups differ.

---

### **Interpretation**
- If the p-value is **less than 0.05**, at least one group mean is significantly different.
- If the p-value is **greater than 0.05**, there is no significant difference between groups.

---

### **Limitations**
- Only tells you if a difference exists, not which groups differ (post-hoc tests are needed).
- Sensitive to outliers and non-normality.

---

### **Post-Hoc Tests**
- **Tukey’s HSD**: Compares all possible pairs of groups.
- **Bonferroni**: Adjusts p-values for multiple comparisons.
- **Scheffé**: Conservative test for unequal group sizes.
